{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a645d7",
   "metadata": {},
   "source": [
    "# The Truth Seeker\n",
    "\n",
    "A story in three simulations about bias, evidence, and belief.\n",
    "\n",
    "---\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In a world full of noisy data, how do we find the truth?\n",
    "\n",
    "This project explores three classic Bayesian dilemmas:\n",
    "\n",
    "1. **Simulation 1** – _How Much Evidence Do You Need?_  \n",
    "   A coin is flipped over and over. Can you find the true bias?\n",
    "\n",
    "2. **Simulation 2** – _How Sure Should You Be?_  \n",
    "   A medical test comes back positive. But how likely is it that the patient really has the disease?\n",
    "\n",
    "3. **Simulation 3** – _How Wrong Are You?_  \n",
    "   A suspect is identified in a lineup. Do you trust the witness or your own prior beliefs?\n",
    "\n",
    "Each simulation explores the tension between **prior assumptions and new data**, showing how our beliefs update (or fail to).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bfc4d40-8aa0-44a4-ba78-3ca6efda66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde8b0a-182b-4d8b-9bf1-c71735574a14",
   "metadata": {},
   "source": [
    "## Simulation 1: How Much Evidence Do You Need?\n",
    "\n",
    "You're trying to figure out whether a coin is fair.\n",
    "\n",
    "But you're not starting from scratch — you already have a belief about its bias.\n",
    "\n",
    "- What if you think it's a fair coin?\n",
    "- What if you suspect it's heavily weighted toward tails?\n",
    "- And what happens when the coin starts coming up heads again and again?\n",
    "\n",
    "Use the sliders to set your prior belief about the coin's fairness and the number of observed flips.\n",
    "\n",
    "Then see how your belief updates as more evidence comes in.\n",
    "\n",
    "How many flips does it take before you're convinced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af809a-cb79-49ba-9e27-4968f4a78e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "true_p = 0.7\n",
    "\n",
    "# Flip 50 times\n",
    "np.random.seed(42)\n",
    "flips = np.random.binomial(1, true_p, size=50)\n",
    "\n",
    "# Count outcomes\n",
    "heads = np.cumsum(flips)\n",
    "tails = np.cumsum(1 - flips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c886d-6fb9-40f1-bc14-4b5934008481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_belief(prior_a, prior_b, flips, step, color):\n",
    "    h = np.sum(flips[:step])\n",
    "    t = step - h\n",
    "    x = np.linspace(0, 1, 500)\n",
    "    posterior = beta(prior_a + h, prior_b + t)\n",
    "    plt.plot(x, posterior.pdf(x), label=f'After {step} flips', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ca1c3-4e3b-4a08-8937-69280581aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior Set up\n",
    "prior_a, prior_b = 1, 1  # Uniform prior\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Belief updates at various stages\n",
    "plot_belief(prior_a, prior_b, flips, 1, 'gray')\n",
    "plot_belief(prior_a, prior_b, flips, 5, 'orange')\n",
    "plot_belief(prior_a, prior_b, flips, 15, 'green')\n",
    "plot_belief(prior_a, prior_b, flips, 30, 'blue')\n",
    "plot_belief(prior_a, prior_b, flips, 50, 'red')\n",
    "\n",
    "plt.title(\"Updating Belief About Coin Bias (Posterior)\")\n",
    "plt.xlabel(\"Bias (Probability of Heads)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1609f-db5b-4bcd-bdf7-e38900c5f1ca",
   "metadata": {},
   "source": [
    "## Simulation 1B: When Strong Priors Trap You\n",
    "\n",
    "Sometimes, our prior beliefs are so strong that we ignore the evidence.\n",
    "\n",
    "Imagine a scientist who refuses to believe the coin is unfair. They start with a prior that the coin is almost certainly fair. But in reality, the coin is biased (80% chance of heads).\n",
    "\n",
    "Let’s see how long it takes their belief to shift and whether it ever does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a733ae-cd0e-415a-a09e-bec525b76422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a biased coin: 80% heads, 20% tails\n",
    "np.random.seed(42)\n",
    "n_flips = 50\n",
    "p_heads_actual = 0.8\n",
    "flips = np.random.choice([1, 0], size=n_flips, p=[p_heads_actual, 1 - p_heads_actual])\n",
    "\n",
    "# Strong prior: believes coin is 50/50 with extreme confidence\n",
    "alpha_prior = 500\n",
    "beta_prior = 500\n",
    "\n",
    "# Track posterior updates\n",
    "posterior_alphas = []\n",
    "posterior_betas = []\n",
    "\n",
    "for i in range(1, n_flips + 1):\n",
    "    heads = np.sum(flips[:i])\n",
    "    tails = i - heads\n",
    "    posterior_alphas.append(alpha_prior + heads)\n",
    "    posterior_betas.append(beta_prior + tails)\n",
    "\n",
    "# Plot posterior after each flip\n",
    "x = np.linspace(0, 1, 500)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in [1, 5, 10, 20, 50]:\n",
    "    posterior = beta(posterior_alphas[i-1], posterior_betas[i-1])\n",
    "    plt.plot(x, posterior.pdf(x), label=f'After {i} flips')\n",
    "\n",
    "plt.title(\"Posterior Belief with Overconfident Prior (Fair Coin)\")\n",
    "plt.xlabel(\"Probability of Heads\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2fc51-123e-4823-aeac-3a2051d1056c",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "Despite flipping the coin 50 times and getting mostly heads, the posterior still clusters around 0.5. This is because the prior belief was extremely confident the coin is fair. It takes a lot of evidence to overcome that.\n",
    "\n",
    "This is the danger of overconfident priors: they can delay or distort learning, even when reality is trying to tell you otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e1ac78-ee66-451c-8246-39144dbccf8f",
   "metadata": {},
   "source": [
    "## Simulation 1C: Tuning Our Own Prior\n",
    "\n",
    "By changing the sliders below we're adjusting how confident the person is before seeing any coin flips.\n",
    "\n",
    "- A small prior (e.g., Alpha=1, Beta=1) means you're flexible.\n",
    "- A big prior (e.g., Alpha=50, Beta=50) means you're confident the coin is fair.\n",
    "\n",
    "This shows how Bayesian inference works in action and how much influence our starting belief really has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccd79c-1ca4-46b1-ade0-ade4ec57505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_coin_simulation(alpha_prior, beta_prior, n_flips):\n",
    "    # Simulate biased coin (80% heads)\n",
    "    np.random.seed(42)\n",
    "    p_heads_actual = 0.8\n",
    "    flips = np.random.choice([1, 0], size=n_flips, p=[p_heads_actual, 1 - p_heads_actual])\n",
    "\n",
    "    heads = np.sum(flips)\n",
    "    tails = n_flips - heads\n",
    "\n",
    "    alpha_post = alpha_prior + heads\n",
    "    beta_post = beta_prior + tails\n",
    "\n",
    "    x = np.linspace(0, 1, 500)\n",
    "    posterior = beta(alpha_post, beta_post)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, posterior.pdf(x), label=f'Posterior after {n_flips} flips')\n",
    "    plt.axvline(p_heads_actual, color='red', linestyle='--', label='True Bias (0.8)')\n",
    "    plt.title(f\"Posterior Belief\\nPrior: Beta({alpha_prior}, {beta_prior}), Flips: {n_flips}\")\n",
    "    plt.xlabel(\"Probability of Heads\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d69ceb7-62bc-4f14-ab1f-68326cbe90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_slider = widgets.IntSlider(value=1, min=1, max=100, step=1, description='Alpha (heads)')\n",
    "beta_slider = widgets.IntSlider(value=1, min=1, max=100, step=1, description='Beta (tails)')\n",
    "flip_slider = widgets.IntSlider(value=10, min=1, max=100, step=1, description='Num Flips')\n",
    "\n",
    "widgets.interact(interactive_coin_simulation,\n",
    "                 alpha_prior=alpha_slider,\n",
    "                 beta_prior=beta_slider,\n",
    "                 n_flips=flip_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b1526-c88f-4dd5-9c6e-20ee2268d20a",
   "metadata": {},
   "source": [
    "## Simulation 2: How Sure Should You Be?\n",
    "\n",
    "A medical test just came back positive.\n",
    "\n",
    "But does that mean the patient really has the disease?\n",
    "\n",
    "- The disease is rare: only 1 in 1,000 people have it.\n",
    "- The test is highly accurate but not perfect.\n",
    "- Even a small false positive rate can lead to surprising results.\n",
    "\n",
    "Use the sliders to set the disease prevalence, test accuracy, and false positive rate.\n",
    "\n",
    "Then see how Bayes’ Theorem updates your belief after a positive test.\n",
    "\n",
    "You might be shocked at how low the actual chance of disease still is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e49ed1-599d-404b-b603-ca1d0c21f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "prior = 0.01             # P(Disease)\n",
    "sensitivity = 0.99       # P(Test + | Disease)\n",
    "specificity = 0.95       # P(Test - | No Disease)\n",
    "\n",
    "# Use Bayes' Theorem\n",
    "# P(Disease | Test +) = (P(Test + | Disease) * P(Disease)) / P(Test +)\n",
    "\n",
    "# Compute P(Test +)\n",
    "p_test_positive = (sensitivity * prior) + ((1 - specificity) * (1 - prior))\n",
    "\n",
    "# Compute posterior\n",
    "posterior = (sensitivity * prior) / p_test_positive\n",
    "\n",
    "# Print result\n",
    "print(f\"After a positive test, the probability the patient actually has the disease is: {posterior:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b87064-4a79-413f-b2d7-5e00ea9598e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Simulate 10,000 patients\n",
    "n = 10000\n",
    "has_disease = np.random.rand(n) < prior\n",
    "test_positive = (has_disease & (np.random.rand(n) < sensitivity)) | \\\n",
    "                (~has_disease & (np.random.rand(n) < (1 - specificity)))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist([has_disease[test_positive], ~has_disease[test_positive]],\n",
    "         label=['True Positive', 'False Positive'],\n",
    "         color=['green', 'red'],\n",
    "         bins=2, rwidth=0.7)\n",
    "plt.xticks([0, 1], ['False Positive', 'True Positive'])\n",
    "plt.title(\"Who actually has the disease among positive test cases?\")\n",
    "plt.ylabel(\"Number of people\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076635a",
   "metadata": {},
   "source": [
    "## Trying It Ourself\n",
    "\n",
    "We can adjust the parameters below to see how changing the rarity of the disease and test accuracy affects risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d6dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_disease_test(prior_disease, sensitivity, specificity):\n",
    "    # Convert percent to fraction\n",
    "    p_disease = prior_disease / 100\n",
    "    p_no_disease = 1 - p_disease\n",
    "    sens = sensitivity / 100\n",
    "    spec = specificity / 100\n",
    "\n",
    "    # Bayes rule: P(Disease | Positive Test)\n",
    "    p_positive = p_disease * sens + p_no_disease * (1 - spec)\n",
    "    posterior = (p_disease * sens) / p_positive\n",
    "\n",
    "    # Bar plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar([\"P(Disease | Positive)\"], [posterior], color=\"orange\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f\"Posterior Probability: {posterior:.2%}\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "407d9f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Prior %', min=1), IntSlider(value=99, description='Sensi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.bayes_disease_test(prior_disease, sensitivity, specificity)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_slider = widgets.IntSlider(value=1, min=1, max=100, step=1, description='Prior %')\n",
    "sensitivity_slider = widgets.IntSlider(value=99, min=80, max=100, step=1, description='Sensitivity')\n",
    "specificity_slider = widgets.IntSlider(value=95, min=80, max=100, step=1, description='Specificity')\n",
    "\n",
    "widgets.interact(bayes_disease_test,\n",
    "                 prior_disease=prior_slider,\n",
    "                 sensitivity=sensitivity_slider,\n",
    "                 specificity=specificity_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6d455b-5f6e-4240-9180-fea873efed87",
   "metadata": {},
   "source": [
    "## Simulation 3: How Wrong Are You?\n",
    "\n",
    "A witness identifies someone in a police lineup.\n",
    "But how reliable is that identification?\n",
    "\n",
    "- What if only 1 in 5 people are actually guilty?\n",
    "- What if witnesses mistakenly identify innocent people 25% of the time?\n",
    "- What if you strongly believe in their guilt before even seeing the ID?\n",
    "\n",
    "We can use the sliders below to simulate a real-world dilemma of bias vs evidence.\n",
    "\n",
    "How likely is it that the suspect is actually guilty?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e32ab-17ef-469d-a593-5c76ce8f4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "prior_guilt = 1 / 5           # 1 in 5 people is actually guilty\n",
    "accuracy_if_guilty = 0.8      # P(ID | Guilty)\n",
    "false_id_if_innocent = 0.25   # P(ID | Innocent)\n",
    "\n",
    "# Total probability of ID being made\n",
    "p_id = (accuracy_if_guilty * prior_guilt) + (false_id_if_innocent * (1 - prior_guilt))\n",
    "\n",
    "# Bayes' Theorem\n",
    "posterior = (accuracy_if_guilty * prior_guilt) / p_id\n",
    "\n",
    "print(f\"Probability the suspect is guilty given the ID: {posterior:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2995d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guilt_posterior(prior_percent, witness_accuracy, false_id_rate):\n",
    "    # Convert to probabilities\n",
    "    prior = prior_percent / 100\n",
    "    p_id_given_guilty = witness_accuracy / 100\n",
    "    p_id_given_innocent = false_id_rate / 100\n",
    "\n",
    "    # Total probability of ID\n",
    "    p_id = (p_id_given_guilty * prior) + (p_id_given_innocent * (1 - prior))\n",
    "\n",
    "    # Bayes' Theorem\n",
    "    posterior = (p_id_given_guilty * prior) / p_id\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar([\"P(Guilty | ID)\"], [posterior], color='purple')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title(f\"Posterior Probability: {posterior:.2%}\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54be1b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3291cc28903b424dbbfc9fd2e00cd98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=20, description='Prior Guilt %', min=1), IntSlider(value=80, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.guilt_posterior(prior_percent, witness_accuracy, false_id_rate)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_slider = widgets.IntSlider(value=20, min=1, max=100, step=1, description='Prior Guilt %')\n",
    "accuracy_slider = widgets.IntSlider(value=80, min=50, max=100, step=1, description='Witness Accuracy')\n",
    "false_id_slider = widgets.IntSlider(value=25, min=0, max=100, step=1, description='False ID Rate')\n",
    "\n",
    "widgets.interact(guilt_posterior,\n",
    "                 prior_percent=prior_slider,\n",
    "                 witness_accuracy=accuracy_slider,\n",
    "                 false_id_rate=false_id_slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
